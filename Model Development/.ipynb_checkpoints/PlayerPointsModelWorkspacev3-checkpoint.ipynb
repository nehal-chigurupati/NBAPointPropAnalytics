{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bcc9412-0c97-4b3c-a4cb-34cf6c1332f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.static import teams, players\n",
    "from nba_api.stats.endpoints import playercareerstats, leaguegamefinder, playergamelog, boxscoreadvancedv3, teamestimatedmetrics, playerestimatedmetrics\n",
    "from nba_api.stats.library.parameters import Season, SeasonType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1a1a2d-fe59-4969-ae2f-ac419ea61bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import statsmodels.api as sm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import sklearn\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34dfc5c0-8435-43ae-b6cc-ddf83381e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict above/below this number\n",
    "point_threshold = \"27.5\"\n",
    "player_full_name = \"Tyrese Haliburton\"\n",
    "player_team_abbr = \"IND\"\n",
    "opp_team_abbrev = \"BOS\"\n",
    "game_date = \"DEC 04, 2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e86b6047-ac43-4585-adb6-5426a536b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch player data\n",
    "player_details = [p for p in players.get_players() if p[\"full_name\"] == player_full_name][0]\n",
    "\n",
    "career_stats = playercareerstats.PlayerCareerStats(player_id=player_details['id']).get_data_frames()[0]\n",
    "\n",
    "seasons = career_stats['SEASON_ID']\n",
    "\n",
    "season_data = {}\n",
    "for s in seasons:\n",
    "    season_data[s] = playergamelog.PlayerGameLog(player_id=player_details['id'], season=s, season_type_all_star=SeasonType.regular).get_data_frames()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e8f671-74dd-4eb1-b8df-1853b5676493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor each game, we want to extract the following information for training:\\n1. Opponent team defensive rating\\n2. Player team offensive rating\\n3. Player offensive rating\\n4. Player usage rate\\n5. Days since last game\\n6. Game number\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "For each game, we want to extract the following information for training:\n",
    "1. Opponent team defensive rating\n",
    "2. Player team offensive rating\n",
    "3. Player offensive rating\n",
    "4. Player usage rate\n",
    "5. Days since last game\n",
    "6. Game number\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16af7c2b-9860-4a0b-9e40-ffbe033e1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Form training arrays\n",
    "X_currseason = []\n",
    "X_allseasons = []\n",
    "opp_def_rating_allseasons = []\n",
    "opp_def_rating_currseason = []\n",
    "team_off_rating_allseasons = []\n",
    "team_off_rating_currseason = []\n",
    "player_off_rating_allseasons = []\n",
    "player_off_rating_currseason = []\n",
    "player_usage_rate_allseasons = []\n",
    "player_usage_rate_currseason = []\n",
    "days_since_last_game_allseasons = []\n",
    "days_since_last_game_currseason = []\n",
    "game_numbers_allseasons = []\n",
    "game_numbers_currseason = []\n",
    "Y_regr_currseason = []\n",
    "Y_class_currseason = []\n",
    "Y_regr_allseasons = []\n",
    "Y_class_allseasons = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "131597e4-5f2b-4c77-8578-03d6cfa945a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect data. There's a different approach here. \n",
    "We are going to build two models, one predicting exact points (regression), one\n",
    "predicting purely over/under point threshold. Also, we are going to train on two \n",
    "different timeframes of data: player whole career and current season only.\n",
    "\"\"\"\n",
    "for season in season_data.keys():\n",
    "    currSeason = season_data[season]\n",
    "    for ind in currSeason.index:\n",
    "        #Label regressions\n",
    "        Y_regr_allseasons.append(float(currSeason['PTS'][ind]))\n",
    "        \n",
    "        #Get defensive rating\n",
    "        metrics = teamestimatedmetrics.TeamEstimatedMetrics(league_id=\"00\", season=season, season_type = SeasonType.regular).get_data_frames()[0]\n",
    "        opp_abbrev = currSeason['MATCHUP'][ind][-3:]\n",
    "\n",
    "\n",
    "        for i in teams.get_teams():\n",
    "            if i['abbreviation'] == opp_abbrev:\n",
    "                opp_team_id = i['id']\n",
    "                \n",
    "        opp_def_rating_allseasons.append(metrics.loc[metrics[\"TEAM_ID\"] == opp_team_id][\"E_DEF_RATING\"])\n",
    "\n",
    "        #Get team offensive rating\n",
    "        for i in teams.get_teams():\n",
    "            if i['abbreviation'] == currSeason[\"MATCHUP\"][ind][0:3]:\n",
    "                plr_team_id = i['id']\n",
    "\n",
    "        team_off_rating_allseasons.append(metrics.loc[metrics[\"TEAM_ID\"] == plr_team_id][\"E_OFF_RATING\"])\n",
    "        \n",
    "        #Get player offensive rating\n",
    "        player_metrics = playerestimatedmetrics.PlayerEstimatedMetrics(league_id=\"00\", season=season, season_type = SeasonType.regular).get_data_frames()[0]\n",
    "        player_id = player_details['id']\n",
    "\n",
    "        player_off_rating_allseasons.append(player_metrics.loc[player_metrics[\"PLAYER_ID\"] == player_id][\"E_OFF_RATING\"])\n",
    "\n",
    "        #Get player usage rate\n",
    "        player_usage_rate_allseasons.append(player_metrics.loc[player_metrics[\"PLAYER_ID\"] == player_id][\"E_USG_PCT\"])\n",
    "        \n",
    "        #Label classifications\n",
    "        if float(currSeason['PTS'][ind]) > float(point_threshold):\n",
    "            Y_class_allseasons.append(1)\n",
    "        else:\n",
    "            Y_class_allseasons.append(0)\n",
    "            \n",
    "for ind in season_data[\"2023-24\"].index:\n",
    "    #Label regressions\n",
    "    Y_regr_currseason.append(float(season_data[\"2023-24\"]['PTS'][ind]))\n",
    "    \n",
    "    #Get team defensive ratings\n",
    "    metrics = teamestimatedmetrics.TeamEstimatedMetrics(league_id=\"00\", season=\"2023-24\", season_type = SeasonType.regular).get_data_frames()[0]\n",
    "    opp_abbrev = season_data[\"2023-24\"][\"MATCHUP\"][ind][-3:]\n",
    "\n",
    "    for i in teams.get_teams():\n",
    "        if i['abbreviation'] == opp_abbrev:\n",
    "            opp_team_id = i['id']\n",
    "\n",
    "    opp_def_rating_currseason.append(metrics.loc[metrics[\"TEAM_ID\"] == opp_team_id][\"E_DEF_RATING\"])\n",
    "\n",
    "    #Get team offensive ratings\n",
    "    for i in teams.get_teams():\n",
    "        if i['abbreviation'] == currSeason[\"MATCHUP\"][ind][0:3]:\n",
    "            plr_team_id = i['id']\n",
    "\n",
    "    team_off_rating_currseason.append(metrics.loc[metrics[\"TEAM_ID\"] == plr_team_id][\"E_OFF_RATING\"])\n",
    "\n",
    "    #Get player offensive rating\n",
    "    player_metrics = playerestimatedmetrics.PlayerEstimatedMetrics(league_id=\"00\", season=\"2023-24\", season_type = SeasonType.regular).get_data_frames()[0]\n",
    "    player_id = player_details['id']\n",
    "\n",
    "    player_off_rating_currseason.append(player_metrics.loc[player_metrics[\"PLAYER_ID\"] == player_id][\"E_OFF_RATING\"])\n",
    "\n",
    "    #Get player usage rate\n",
    "    player_usage_rate_currseason.append(player_metrics.loc[player_metrics[\"PLAYER_ID\"] == player_id][\"E_USG_PCT\"])\n",
    "    \n",
    "    #Label classifications\n",
    "    if float(season_data[\"2023-24\"]['PTS'][ind]) > float(point_threshold):\n",
    "        Y_class_currseason.append(1)\n",
    "    else:\n",
    "        Y_class_currseason.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a087b5d0-e1c9-4a83-9c09-8a30ef320600",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = {\n",
    "    \"JAN\": 1,\n",
    "    \"FEB\": 2,\n",
    "    \"MAR\": 3,\n",
    "    \"APR\": 4,\n",
    "    \"MAY\": 5,\n",
    "    \"JUN\": 6,\n",
    "    \"JUL\": 7,\n",
    "    \"AUG\": 8,\n",
    "    \"OCT\": 10,\n",
    "    \"NOV\": 11,\n",
    "    \"DEC\": 12\n",
    "}\n",
    "def convert_human_date(d):\n",
    "    month = months[d[0:3]]\n",
    "    day = int(d[4:6])\n",
    "    year = int(d[8:])\n",
    "\n",
    "    return date(year, month, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da88ccd-8b1b-4f43-aa83-92f8b9daf0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_between_dates(d1, d2):\n",
    "    return int((d2 - d1).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "303c32d6-ce20-4052-b268-1318bf6b45fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default days of rest set for the first game of the season:\n",
    "first_game_rest = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7745126-a571-429f-8389-060bb25bb4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute days since last game\n",
    "for season in season_data.keys():\n",
    "    currSeason = season_data[season]\n",
    "    for ind in currSeason.index:\n",
    "        if (ind + 1) == len(currSeason.index):\n",
    "            days_since_last_game_allseasons.append(first_game_rest)\n",
    "        else:\n",
    "            currGameDate = convert_human_date(str(currSeason[\"GAME_DATE\"][ind]))\n",
    "            lastGameDate = convert_human_date(str(currSeason[\"GAME_DATE\"][ind+1]))\n",
    "            days_since_last_game_allseasons.append(distance_between_dates(lastGameDate, currGameDate))\n",
    "for ind in season_data[\"2023-24\"].index:\n",
    "    if (ind + 1) == len(season_data[\"2023-24\"].index):\n",
    "        days_since_last_game_currseason.append(first_game_rest)\n",
    "    else:\n",
    "        currGameDate = convert_human_date(str(season_data['2023-24'][\"GAME_DATE\"][ind]))\n",
    "        lastGameDate = convert_human_date(str(season_data['2023-24'][\"GAME_DATE\"][ind+1]))\n",
    "        days_since_last_game_currseason.append(distance_between_dates(lastGameDate, currGameDate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36cd9905-23b8-4f3a-80ad-6aabdcd825cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the game number, in terms of the number of games that player has played\n",
    "for season in season_data.keys():\n",
    "    for ind in season_data[season].index:\n",
    "        game_numbers_allseasons.append(len(season_data[season].index) - ind)\n",
    "\n",
    "for ind in season_data[\"2023-24\"].index:\n",
    "    game_numbers_currseason.append(len(season_data[\"2023-24\"].index) - ind)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82f05ed0-eb50-4540-a60e-d8c3dd524446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default average ppg since start of season\n",
    "default_first_game_ppg = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12f1ae13-9897-4a55-a7c2-55b08df4f99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wt/9_6pdt8n2kz5f1cv6bqysq440000gn/T/ipykernel_3182/4020995574.py:5: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  tpl = (float(opp_def_rating_allseasons[i]), float(team_off_rating_allseasons[i]), float(player_off_rating_allseasons[i]), float(player_usage_rate_allseasons[i]), float(days_since_last_game_allseasons[i]), float(game_numbers_allseasons[i]))\n",
      "/var/folders/wt/9_6pdt8n2kz5f1cv6bqysq440000gn/T/ipykernel_3182/4020995574.py:9: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  tpl = (float(opp_def_rating_currseason[i]), float(team_off_rating_currseason[i]), float(player_off_rating_currseason[i]), float(player_usage_rate_currseason[i]), float(days_since_last_game_currseason[i]), float(game_numbers_currseason[i]))\n"
     ]
    }
   ],
   "source": [
    "#Zip together all the training input data\n",
    "X_allseasons = []\n",
    "X_currseason = []\n",
    "for i in range(len(game_numbers_allseasons)):\n",
    "    tpl = (float(opp_def_rating_allseasons[i]), float(team_off_rating_allseasons[i]), float(player_off_rating_allseasons[i]), float(player_usage_rate_allseasons[i]), float(days_since_last_game_allseasons[i]), float(game_numbers_allseasons[i]))\n",
    "    X_allseasons.append(tpl)\n",
    "\n",
    "for i in range(len(game_numbers_currseason)):\n",
    "    tpl = (float(opp_def_rating_currseason[i]), float(team_off_rating_currseason[i]), float(player_off_rating_currseason[i]), float(player_usage_rate_currseason[i]), float(days_since_last_game_currseason[i]), float(game_numbers_currseason[i]))\n",
    "    X_currseason.append(tpl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e6e8d10-d02d-461b-ad0f-50dd3b0cb561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.17849779e-01 5.32424172e-02 1.50497608e-02 1.14535192e-02\n",
      " 2.40447152e-03 5.24759352e-08]\n"
     ]
    }
   ],
   "source": [
    "#Run PCA to determine which predictor variables to include, for all seasons\n",
    "pca = PCA(n_components = 6)\n",
    "pca.fit(X_allseasons)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61b4f6ae-86a7-4923-b00c-c3e69003b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wt/9_6pdt8n2kz5f1cv6bqysq440000gn/T/ipykernel_3182/4277634942.py:5: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  tpl = (float(opp_def_rating_allseasons[i]), float(team_off_rating_allseasons[i]), float(player_off_rating_allseasons[i]), float(player_usage_rate_allseasons[i]))\n",
      "/var/folders/wt/9_6pdt8n2kz5f1cv6bqysq440000gn/T/ipykernel_3182/4277634942.py:9: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  tpl = (float(opp_def_rating_currseason[i]), float(team_off_rating_currseason[i]), float(player_off_rating_currseason[i]), float(player_usage_rate_currseason[i]))\n"
     ]
    }
   ],
   "source": [
    "#So then let's reform the data, without game number and days since last game from the data\n",
    "X_allseasons = []\n",
    "X_currseason = []\n",
    "for i in range(len(game_numbers_allseasons)):\n",
    "    tpl = (float(opp_def_rating_allseasons[i]), float(team_off_rating_allseasons[i]), float(player_off_rating_allseasons[i]), float(player_usage_rate_allseasons[i]))\n",
    "    X_allseasons.append(tpl)\n",
    "\n",
    "for i in range(len(game_numbers_currseason)):\n",
    "    tpl = (float(opp_def_rating_currseason[i]), float(team_off_rating_currseason[i]), float(player_off_rating_currseason[i]), float(player_usage_rate_currseason[i]))\n",
    "    X_currseason.append(tpl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37353f62-8979-4aa1-a785-37130cba911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let's start preprocessing the data\n",
    "Y_regr_allseasons = pd.DataFrame(Y_regr_allseasons)\n",
    "Y_regr_currseason = pd.DataFrame(Y_regr_currseason)\n",
    "Y_class_allseasons = pd.DataFrame(Y_class_allseasons)\n",
    "Y_class_currseason = pd.DataFrame(Y_class_currseason)\n",
    "\n",
    "X_allseasons = pd.DataFrame(X_allseasons)\n",
    "X_currseason = pd.DataFrame(X_currseason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9fc3dab-b64d-4a3d-919d-011031d58c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_regr_allseasons_train, X_regr_allseasons_test, Y_regr_allseasons_train, Y_regr_allseasons_test = train_test_split(X_allseasons, Y_regr_allseasons, test_size=.25)\n",
    "X_class_allseasons_train, X_class_allseasons_test, Y_class_allseasons_train, Y_class_allseasons_test = train_test_split(X_allseasons, Y_class_allseasons, test_size=.25)\n",
    "X_regr_currseason_train, X_regr_currseason_test, Y_regr_currseason_train, Y_regr_currseason_test = train_test_split(X_currseason, Y_regr_currseason, test_size=.25)\n",
    "X_class_currseason_train, X_class_currseason_test, Y_class_currseason_train, Y_class_currseason_test = train_test_split(X_currseason, Y_class_currseason, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00a21334-29b8-4696-8138-1b7fd8f79eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's start with the classification models. We'll check with 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e694e842-53f3-4efa-82d8-0982800a19e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9038306451612904\n"
     ]
    }
   ],
   "source": [
    "#all seasons SVC. Has a great cross-validation score\n",
    "svc = SVC()\n",
    "scores = cross_val_score(svc, X_class_allseasons_train, Y_class_allseasons_train.values.ravel(), cv=5)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b86ed9f7-b2fa-4db5-bfaf-8533d8bf43fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66666667 0.66666667 0.5        0.5        0.5       ]\n"
     ]
    }
   ],
   "source": [
    "#current season SVC. Not great. \n",
    "svc = SVC()\n",
    "scores = cross_val_score(svc, X_class_currseason_train, Y_class_currseason_train.values.ravel(), cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d3d8a7c-919f-4df6-ade1-d8e33658d0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8651209677419354\n"
     ]
    }
   ],
   "source": [
    "#All seasons logistic classifier. Pretty good!\n",
    "log = LogisticRegression()\n",
    "scores = cross_val_score(log, X_class_allseasons_train, Y_class_allseasons_train.values.ravel(), cv=5)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd327a8d-44cd-487c-85cd-0a6abd216d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33333333 0.33333333 0.5        0.5        0.5       ]\n"
     ]
    }
   ],
   "source": [
    "#Current season logistic classifier. Bad\n",
    "log = LogisticRegression()\n",
    "scores = cross_val_score(log, X_class_currseason_train, Y_class_currseason_train.values.ravel(), cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7584c636-06cb-4109-9f56-f7ce06cb867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What's happening is a lack of data problem. There have been fewer than twenty games this season for any given team. So let's use all season data now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed3eabaf-3dcf-4c8c-a7d5-57978f4d45f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8715725806451612\n"
     ]
    }
   ],
   "source": [
    "#All season random forest classifier. Not as good as SVC or logistic classifier. \n",
    "rcf = RandomForestClassifier()\n",
    "scores = cross_val_score(rcf, X_class_allseasons_train, Y_class_allseasons_train.values.ravel(), cv=5)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e26ab9f6-7850-480d-8042-54bf598ae4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8522177419354838\n"
     ]
    }
   ],
   "source": [
    "#Gradient boosting. Not as great as SVC or logistic classifier.\n",
    "gbc = GradientBoostingClassifier()\n",
    "scores = cross_val_score(gbc, X_class_allseasons_train, Y_class_allseasons_train.values.ravel(), cv=5)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7eae474-1809-4fa2-aa7d-dcebbe5392ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.878024193548387\n"
     ]
    }
   ],
   "source": [
    "#Ridge classifier. This is pretty good too. \n",
    "rc = RidgeClassifier()\n",
    "scores = cross_val_score(rc, X_class_allseasons_train, Y_class_allseasons_train.values.ravel(), cv=5)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f587dac3-39a5-4b2b-90bd-c1984138ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let's try regression on allseasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e8049cc-efa8-4d2e-acc1-d95ee2b45ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>0</td>        <th>  R-squared (uncentered):</th>      <td>   0.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.839</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   204.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 04 Dec 2023</td> <th>  Prob (F-statistic):</th>          <td>4.52e-60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:04:22</td>     <th>  Log-Likelihood:    </th>          <td> -533.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   156</td>      <th>  AIC:               </th>          <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   152</td>      <th>  BIC:               </th>          <td>   1087.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th> <td>   -0.1411</td> <td>    0.193</td> <td>   -0.733</td> <td> 0.465</td> <td>   -0.522</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th> <td>    1.4426</td> <td>    0.897</td> <td>    1.608</td> <td> 0.110</td> <td>   -0.330</td> <td>    3.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th> <td>   -1.5011</td> <td>    1.070</td> <td>   -1.402</td> <td> 0.163</td> <td>   -3.616</td> <td>    0.614</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3</th> <td>  196.7925</td> <td>   68.856</td> <td>    2.858</td> <td> 0.005</td> <td>   60.754</td> <td>  332.831</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.266</td> <th>  Durbin-Watson:     </th> <td>   2.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.322</td> <th>  Jarque-Bera (JB):  </th> <td>   1.820</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.235</td> <th>  Prob(JB):          </th> <td>   0.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.243</td> <th>  Cond. No.          </th> <td>2.21e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[3] The condition number is large, 2.21e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        0         & \\textbf{  R-squared (uncentered):}      &     0.843   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.839   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       }          &     204.4   \\\\\n",
       "\\textbf{Date:}             & Mon, 04 Dec 2023 & \\textbf{  Prob (F-statistic):}          &  4.52e-60   \\\\\n",
       "\\textbf{Time:}             &     21:04:22     & \\textbf{  Log-Likelihood:    }          &   -533.16   \\\\\n",
       "\\textbf{No. Observations:} &         156      & \\textbf{  AIC:               }          &     1074.   \\\\\n",
       "\\textbf{Df Residuals:}     &         152      & \\textbf{  BIC:               }          &     1087.   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "           & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{0} &      -0.1411  &        0.193     &    -0.733  &         0.465        &       -0.522    &        0.239     \\\\\n",
       "\\textbf{1} &       1.4426  &        0.897     &     1.608  &         0.110        &       -0.330    &        3.215     \\\\\n",
       "\\textbf{2} &      -1.5011  &        1.070     &    -1.402  &         0.163        &       -3.616    &        0.614     \\\\\n",
       "\\textbf{3} &     196.7925  &       68.856     &     2.858  &         0.005        &       60.754    &      332.831     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  2.266 & \\textbf{  Durbin-Watson:     } &    2.048  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.322 & \\textbf{  Jarque-Bera (JB):  } &    1.820  \\\\\n",
       "\\textbf{Skew:}          &  0.235 & \\textbf{  Prob(JB):          } &    0.403  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.243 & \\textbf{  Cond. No.          } & 2.21e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [3] The condition number is large, 2.21e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      0   R-squared (uncentered):                   0.843\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.839\n",
       "Method:                 Least Squares   F-statistic:                              204.4\n",
       "Date:                Mon, 04 Dec 2023   Prob (F-statistic):                    4.52e-60\n",
       "Time:                        21:04:22   Log-Likelihood:                         -533.16\n",
       "No. Observations:                 156   AIC:                                      1074.\n",
       "Df Residuals:                     152   BIC:                                      1087.\n",
       "Df Model:                           4                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "0             -0.1411      0.193     -0.733      0.465      -0.522       0.239\n",
       "1              1.4426      0.897      1.608      0.110      -0.330       3.215\n",
       "2             -1.5011      1.070     -1.402      0.163      -3.616       0.614\n",
       "3            196.7925     68.856      2.858      0.005      60.754     332.831\n",
       "==============================================================================\n",
       "Omnibus:                        2.266   Durbin-Watson:                   2.048\n",
       "Prob(Omnibus):                  0.322   Jarque-Bera (JB):                1.820\n",
       "Skew:                           0.235   Prob(JB):                        0.403\n",
       "Kurtosis:                       3.243   Cond. No.                     2.21e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[3] The condition number is large, 2.21e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear regression\n",
    "OLS_model = sm.OLS(Y_regr_allseasons_train, X_regr_allseasons_train, hasconst=None)\n",
    "OLS_results = OLS_model.fit()\n",
    "OLS_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa4b5fbf-1369-46e7-8c7d-58b23522225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up constants for weighted linear regression\n",
    "y_resid = [abs(resid) for resid in OLS_results.resid]\n",
    "\n",
    "X_resid = sm.add_constant(OLS_results.fittedvalues)\n",
    "\n",
    "mod_resid = sm.OLS(y_resid, X_resid)\n",
    "res_resid = mod_resid.fit()\n",
    "\n",
    "mod_fv = res_resid.fittedvalues\n",
    "\n",
    "weights = 1 / (mod_fv**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d19df15-00b8-4363-8247-2eb9fc39e9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>0</td>        <th>  R-squared (uncentered):</th>      <td>   0.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.839</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   204.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 04 Dec 2023</td> <th>  Prob (F-statistic):</th>          <td>4.52e-60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:05:35</td>     <th>  Log-Likelihood:    </th>          <td> -533.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   156</td>      <th>  AIC:               </th>          <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   152</td>      <th>  BIC:               </th>          <td>   1087.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th> <td>   -0.1411</td> <td>    0.193</td> <td>   -0.733</td> <td> 0.465</td> <td>   -0.522</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th> <td>    1.4426</td> <td>    0.897</td> <td>    1.608</td> <td> 0.110</td> <td>   -0.330</td> <td>    3.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th> <td>   -1.5011</td> <td>    1.070</td> <td>   -1.402</td> <td> 0.163</td> <td>   -3.616</td> <td>    0.614</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3</th> <td>  196.7925</td> <td>   68.856</td> <td>    2.858</td> <td> 0.005</td> <td>   60.754</td> <td>  332.831</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.266</td> <th>  Durbin-Watson:     </th> <td>   2.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.322</td> <th>  Jarque-Bera (JB):  </th> <td>   1.820</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.235</td> <th>  Prob(JB):          </th> <td>   0.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.243</td> <th>  Cond. No.          </th> <td>2.21e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[3] The condition number is large, 2.21e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        0         & \\textbf{  R-squared (uncentered):}      &     0.843   \\\\\n",
       "\\textbf{Model:}            &       WLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.839   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       }          &     204.4   \\\\\n",
       "\\textbf{Date:}             & Mon, 04 Dec 2023 & \\textbf{  Prob (F-statistic):}          &  4.52e-60   \\\\\n",
       "\\textbf{Time:}             &     21:05:35     & \\textbf{  Log-Likelihood:    }          &   -533.16   \\\\\n",
       "\\textbf{No. Observations:} &         156      & \\textbf{  AIC:               }          &     1074.   \\\\\n",
       "\\textbf{Df Residuals:}     &         152      & \\textbf{  BIC:               }          &     1087.   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "           & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{0} &      -0.1411  &        0.193     &    -0.733  &         0.465        &       -0.522    &        0.239     \\\\\n",
       "\\textbf{1} &       1.4426  &        0.897     &     1.608  &         0.110        &       -0.330    &        3.215     \\\\\n",
       "\\textbf{2} &      -1.5011  &        1.070     &    -1.402  &         0.163        &       -3.616    &        0.614     \\\\\n",
       "\\textbf{3} &     196.7925  &       68.856     &     2.858  &         0.005        &       60.754    &      332.831     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  2.266 & \\textbf{  Durbin-Watson:     } &    2.048  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.322 & \\textbf{  Jarque-Bera (JB):  } &    1.820  \\\\\n",
       "\\textbf{Skew:}          &  0.235 & \\textbf{  Prob(JB):          } &    0.403  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.243 & \\textbf{  Cond. No.          } & 2.21e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{WLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [3] The condition number is large, 2.21e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 WLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      0   R-squared (uncentered):                   0.843\n",
       "Model:                            WLS   Adj. R-squared (uncentered):              0.839\n",
       "Method:                 Least Squares   F-statistic:                              204.4\n",
       "Date:                Mon, 04 Dec 2023   Prob (F-statistic):                    4.52e-60\n",
       "Time:                        21:05:35   Log-Likelihood:                         -533.16\n",
       "No. Observations:                 156   AIC:                                      1074.\n",
       "Df Residuals:                     152   BIC:                                      1087.\n",
       "Df Model:                           4                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "0             -0.1411      0.193     -0.733      0.465      -0.522       0.239\n",
       "1              1.4426      0.897      1.608      0.110      -0.330       3.215\n",
       "2             -1.5011      1.070     -1.402      0.163      -3.616       0.614\n",
       "3            196.7925     68.856      2.858      0.005      60.754     332.831\n",
       "==============================================================================\n",
       "Omnibus:                        2.266   Durbin-Watson:                   2.048\n",
       "Prob(Omnibus):                  0.322   Jarque-Bera (JB):                1.820\n",
       "Skew:                           0.235   Prob(JB):                        0.403\n",
       "Kurtosis:                       3.243   Cond. No.                     2.21e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[3] The condition number is large, 2.21e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create WLS model\n",
    "WLS_model = sm.WLS(Y_regr_allseasons_train, X_regr_allseasons_train, hasconst=None)\n",
    "WLS_results = WLS_model.fit()\n",
    "WLS_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32a40571-cffc-4b52-a9df-ee81a0628f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.22392892976206227\n"
     ]
    }
   ],
   "source": [
    "#Random forest regression\n",
    "rfr = RandomForestRegressor()\n",
    "scores = cross_val_score(rfr, X_regr_allseasons_train, Y_regr_allseasons_train.values.ravel(), cv=5)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f13ed4e8-03e6-4adb-ae1c-9d4591cb5d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.22504395478445355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nehalchigurupati/miniconda3/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/nehalchigurupati/miniconda3/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/nehalchigurupati/miniconda3/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/nehalchigurupati/miniconda3/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/nehalchigurupati/miniconda3/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Gradient boosted regression\n",
    "gbr = GradientBoostingRegressor()\n",
    "scores = cross_val_score(gbr, X_regr_allseasons_train, Y_regr_allseasons_train, cv=5)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a95686a-b8b9-4dd4-bab7-7b7bd2cf7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I think the best approach then is to go with the logistic regressor. Cleanly implemented in PlayerPointModelV3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
